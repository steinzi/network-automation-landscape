{"github_data":{"https://github.com/PrefectHQ/prefect":{"contributors":{"count":379,"url":"https://github.com/PrefectHQ/prefect/graphs/contributors"},"description":"Prefect is a workflow orchestration framework for building resilient data pipelines in Python.","generated_at":"2025-11-18T21:54:57.761686139Z","latest_commit":{"ts":"2025-11-18T18:55:09Z","url":"https://github.com/PrefectHQ/prefect/commit/a3db33d4f9ee7a665430ae6017c649d057139bd3"},"participation_stats":[31,22,65,52,35,40,64,48,53,54,61,75,36,66,50,50,35,37,41,59,28,34,26,31,28,13,8,11,27,21,14,37,16,32,23,23,20,26,21,17,27,35,25,35,23,38,28,43,27,23,35,16],"stars":20855,"topics":["automation","data","data-engineering","data-ops","data-science","infrastructure","ml-ops","observability","orchestration","pipeline","prefect","python","workflow","workflow-engine"],"url":"https://github.com/PrefectHQ/prefect","first_commit":{"ts":"2021-07-12T19:36:30Z","url":"https://github.com/PrefectHQ/prefect/commit/5d64e2da1bd11f31d16993ae1730599e13de4016"},"languages":{"Brainfuck":57,"CSS":5115,"Dockerfile":10734,"HTML":2909,"JavaScript":10117,"Jinja":8159,"Just":6714,"Lua":5413,"Mako":589,"Python":17527610,"Shell":10003,"TypeScript":2938673,"Vue":123138},"latest_release":{"ts":"2025-11-14T00:14:01Z","url":"https://github.com/PrefectHQ/prefect/releases/tag/3.6.2"},"license":"Apache License 2.0"},"https://github.com/apache/airflow":{"contributors":{"count":3987,"url":"https://github.com/apache/airflow/graphs/contributors"},"description":"Apache Airflow - A platform to programmatically author, schedule, and monitor workflows","generated_at":"2025-11-18T21:55:09.988432274Z","latest_commit":{"ts":"2025-11-18T21:13:49Z","url":"https://github.com/apache/airflow/commit/14bc0ef6e87b8880351a6b91d77a318acab98436"},"participation_stats":[124,154,126,98,111,53,78,103,93,154,144,146,113,88,171,147,171,185,166,186,223,173,222,156,160,118,140,126,104,126,196,230,220,206,102,116,119,132,134,151,108,144,178,125,123,85,60,153,278,162,222,124],"stars":43236,"topics":["airflow","apache","apache-airflow","automation","dag","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","elt","etl","machine-learning","mlops","orchestration","python","scheduler","workflow","workflow-engine","workflow-orchestration"],"url":"https://github.com/apache/airflow","first_commit":{"ts":"2014-10-06T21:29:38Z","url":"https://github.com/apache/airflow/commit/1047940ca4363b04044c4963b9c88f7632746407"},"languages":{"CSS":15733,"Dockerfile":126041,"Go":157242,"HCL":3786,"HTML":43841,"Java":1443,"JavaScript":336948,"Jinja":76081,"Jupyter Notebook":7288,"Just":2627,"Mako":2684,"Python":45227679,"Shell":229927,"TypeScript":2844451},"latest_release":{"ts":"2025-11-14T14:47:34Z","url":"https://github.com/apache/airflow/releases/tag/3.1.3"},"license":"Apache License 2.0"},"https://github.com/dagster-io/dagster":{"contributors":{"count":623,"url":"https://github.com/dagster-io/dagster/graphs/contributors"},"description":"An orchestration platform for the development, production, and observation of data assets.","generated_at":"2025-11-18T21:55:24.044579487Z","latest_commit":{"ts":"2025-11-18T16:20:57Z","url":"https://github.com/dagster-io/dagster/commit/ea2a5a642f9c99afb32449e549d63189cf52f274"},"participation_stats":[71,63,90,113,108,33,59,119,110,151,83,193,108,119,97,122,134,103,115,127,142,153,134,100,82,111,95,129,113,84,59,120,78,49,44,95,96,106,85,84,55,60,48,39,51,67,66,47,57,42,47,36],"stars":14439,"topics":["analytics","dagster","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","etl","hacktoberfest","metadata","mlops","orchestration","python","scheduler","workflow","workflow-automation"],"url":"https://github.com/dagster-io/dagster","first_commit":{"ts":"2018-04-30T16:30:04Z","url":"https://github.com/dagster-io/dagster/commit/7bd58d800766aad0c0501539b8f6ee3dbf74331c"},"languages":{"ANTLR":12992,"CSS":67964,"Dockerfile":18351,"HTML":8591,"JavaScript":66858,"Jinja":9253,"Jupyter Notebook":77845,"LookML":329353,"Makefile":12998,"Mako":494,"Mustache":14619,"Python":28488263,"Shell":31993,"Smarty":25391,"TypeScript":6727730},"latest_release":{"ts":"2025-11-13T20:53:06Z","url":"https://github.com/dagster-io/dagster/releases/tag/1.12.2"},"license":"Apache License 2.0"},"https://github.com/mage-ai/mage-ai":{"contributors":{"count":151,"url":"https://github.com/mage-ai/mage-ai/graphs/contributors"},"description":"ðŸ§™ Build, run, and manage data pipelines for integrating and transforming data.","generated_at":"2025-11-18T21:55:48.165239490Z","latest_commit":{"ts":"2025-11-17T08:34:09Z","url":"https://github.com/mage-ai/mage-ai/commit/109bc9caf3800121d1a43b39ed9b04aca4806f6a"},"participation_stats":[4,6,1,2,5,0,2,2,7,3,7,4,5,1,7,2,9,1,10,1,5,1,3,4,7,1,3,7,11,6,9,1,1,5,4,3,7,2,3,4,2,9,3,8,2,4,6,2,2,6,7,5],"stars":8557,"topics":["artificial-intelligence","data","data-engineering","data-integration","data-pipelines","data-science","dbt","elt","etl","machine-learning","orchestration","pipeline","pipelines","python","reverse-etl","spark","sql","transformation"],"url":"https://github.com/mage-ai/mage-ai","first_commit":{"ts":"2022-05-16T22:11:41Z","url":"https://github.com/mage-ai/mage-ai/commit/571131f0c298af6d67b03c85a8ea7984c18350d1"},"languages":{"CSS":113518,"Dockerfile":17335,"HTML":1429837,"JavaScript":34527,"Jinja":16315,"Jupyter Notebook":8996,"Makefile":258,"Mako":510,"Python":9181432,"R":134,"SCSS":77261,"Shell":20509,"TypeScript":6093797},"latest_release":{"ts":"2025-09-18T08:10:55Z","url":"https://github.com/mage-ai/mage-ai/releases/tag/0.9.78"},"license":"Apache License 2.0"},"https://github.com/temporalio/temporal":{"contributors":{"count":249,"url":"https://github.com/temporalio/temporal/graphs/contributors"},"description":"Temporal service","generated_at":"2025-11-18T21:56:43.573491836Z","latest_commit":{"ts":"2025-11-18T16:23:25Z","url":"https://github.com/temporalio/temporal/commit/70c2b81dca3c7ca6326d5c4ea8ac1bb9329dc789"},"participation_stats":[44,22,27,28,25,4,2,22,42,39,32,84,25,26,24,33,24,23,23,26,20,16,20,37,28,23,6,47,17,32,13,26,19,21,21,17,22,15,14,15,13,24,14,18,25,26,22,25,20,18,18,29],"stars":16645,"topics":["cronjob-scheduler","distributed-cron","distributed-systems","golang","microservice-framework","microservice-orchestration","microservices-architecture","orchestrator","service-bus","service-fabric","workflow-automation","workflow-engine","workflow-management","workflow-management-system","workflows"],"url":"https://github.com/temporalio/temporal","first_commit":{"ts":"2016-10-24T23:07:32Z","url":"https://github.com/temporalio/temporal/commit/685242e53fb0c0d9cbdd62fc7725418b528506eb"},"languages":{"Go":20223202,"Makefile":30504,"PLpgSQL":32445,"Python":19117,"Shell":36791},"latest_release":{"ts":"2025-10-29T23:47:24Z","url":"https://github.com/temporalio/temporal/releases/tag/v1.29.1"},"license":"MIT License"}},"items":[{"category":"Automation Tooling","homepage_url":"https://dagster.io/","id":"automation-tooling--workflow-dags--dagster","logo":"logos/3030ac89ff80c2737d3e08baa66c14aaf104b39fcb96a137d304a48d2390ca20.png","name":"Dagster","subcategory":"Workflow DAGs","website":"https://dagster.io/","blog_url":"https://dagster.io/blog","description":"Dagster is a data orchestrator for machine learning, analytics, and ETL. It provides a framework for building, testing, and deploying data pipelines with a focus on developer experience and operational excellence.","documentation_url":"https://docs.dagster.io/","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/dagster-io/dagster/discussions","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/dagster-io/dagster","primary":true}],"summary":{"business_use_case":"Enables reliable and maintainable data pipelines with built-in testing, monitoring, and operational features for data-driven network automation","integration":"dbt, Apache Spark, Kubernetes, Docker, various databases and cloud services","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Data Scientists"],"release_rate":"Regular releases with continuous improvements","tags":["data orchestration","ETL","data pipelines","workflow automation","Python-based"],"use_case":"Data pipeline orchestration, ETL/ELT workflows, machine learning pipelines, network automation data processing"}},{"category":"Automation Tooling","homepage_url":"https://prefect.io/","id":"automation-tooling--workflow-dags--prefect","logo":"logos/0adb8100b3649de768b225edb847cc4849e6a0f36d404360d62a92504730a277.svg","name":"Prefect","subcategory":"Workflow DAGs","website":"https://prefect.io/","blog_url":"https://prefect.io/blog","description":"Prefect is a workflow orchestration framework that makes it easy to build, run, and monitor data pipelines. It provides a Python-native approach to workflow automation with strong observability and error handling.","documentation_url":"https://docs.prefect.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/PrefectHQ/prefect","primary":true}],"slack_url":"https://prefect.io/slack","summary":{"business_use_case":"Simplifies complex workflow management with robust error handling, retries, and monitoring for network automation and data processing","integration":"Kubernetes, Docker, AWS, Azure, GCP, dbt, various databases and APIs","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Software Developers"],"release_rate":"Regular releases with active development","tags":["workflow orchestration","Python","data pipelines","distributed computing","observability"],"use_case":"Workflow orchestration, data pipeline automation, network automation tasks, distributed computing"}},{"category":"Automation Tooling","homepage_url":"https://www.mage.ai/","id":"automation-tooling--workflow-dags--mage-ai","logo":"logos/e527409ece1839fb83a01fe5514a5d157b17b29c7c723db7b3fc9bbfe1b6a527.png","name":"Mage.ai","subcategory":"Workflow DAGs","website":"https://www.mage.ai/","blog_url":"https://www.mage.ai/blog","description":"Mage is an open-source data pipeline tool for transforming and integrating data. It provides a modern approach to building and deploying data pipelines with a focus on simplicity and developer experience.","documentation_url":"https://docs.mage.ai/","featured":{"label":"Full Open Source","order":1},"maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/mage-ai/mage-ai","primary":true}],"slack_url":"https://www.mage.ai/chat","summary":{"business_use_case":"Accelerates data pipeline development with a visual interface and code-first approach for network data processing and automation","integration":"Various databases, cloud services, APIs, and data sources","personas":["Data Engineers","Data Analysts","Network Engineers","DevOps Engineers"],"release_rate":"Active development with regular updates","tags":["data pipelines","ETL","open-source","visual interface","Python"],"use_case":"Data pipeline development, ETL/ELT workflows, data transformation, network telemetry processing"}},{"category":"Automation Tooling","homepage_url":"https://airflow.apache.org","id":"automation-tooling--workflow-dags--apache-airflow","logo":"logos/238f83b507400ed1465c4140bafe0e841c81c208bb81a8c66f987b42d429970a.png","name":"Apache Airflow","subcategory":"Workflow DAGs","website":"https://airflow.apache.org","blog_url":"https://airflow.apache.org/blog","description":"Apache Airflow is an open-source platform that allows for the programmatic creation, scheduling, and monitoring of workflows. It is widely used for orchestrating complex data pipelines and automating tasks across a wide range of industries.","documentation_url":"https://airflow.apache.org/docs","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/apache/airflow/discussions","linkedin_url":"https://www.linkedin.com/company/apache-airflow","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/apache/airflow","primary":true}],"slack_url":"https://apache-airflow.slack.com/","summary":{"business_use_case":"Airflow improves operational efficiency by automating tasks and ensuring seamless integration of data sources, enabling faster and more reliable delivery of insights.","integration":"Supports integration with databases, APIs, cloud services, and external systems to create a unified workflow environment.","personas":["Data Engineers","Data Scientists","DevOps Engineers","IT Operations","Business Analysts"],"release_rate":"Regular updates aligned with the latest advancements in data orchestration and cloud technologies.","tags":["workflow orchestration","data pipelines","automation","ETL","cloud integration","task scheduling"],"use_case":"Orchestrating and scheduling data pipelines, managing ETL processes, and automating complex workflows across diverse environments."}},{"category":"Automation Tooling","homepage_url":"https://temporal.io/","id":"automation-tooling--workflow-dags--temporal","logo":"logos/d12d353299e539dd716b2ab211d1b59b23a8ee702cc391bbb3ea6702649e17b5.svg","name":"Temporal","subcategory":"Workflow DAGs","website":"https://temporal.io/","blog_url":"https://temporal.io/blog","description":"Temporal is a microservice orchestration platform that enables developers to build scalable and reliable applications using durable execution.","documentation_url":"https://docs.temporal.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/temporalio/temporal","primary":true}],"slack_url":"https://temporal.io/slack","summary":{"business_use_case":"Simplifies building reliable distributed systems and applications, reducing development time and improving system resilience","integration":"Supports various programming languages (Go, Java, PHP, TypeScript)","personas":["Software Developers","System Architects","DevOps Engineers"],"release_rate":"Regular releases with new features and improvements","tags":["workflow engine","microservices","distributed systems","durable execution","open-source"],"use_case":"Microservice orchestration, workflow automation, distributed systems coordination"},"youtube_url":"https://www.youtube.com/temporalio"}]}