{"github_data":{"https://github.com/PrefectHQ/prefect":{"contributors":{"count":379,"url":"https://github.com/PrefectHQ/prefect/graphs/contributors"},"description":"Prefect is a workflow orchestration framework for building resilient data pipelines in Python.","generated_at":"2025-11-20T17:36:26.430069297Z","latest_commit":{"ts":"2025-11-20T16:17:18Z","url":"https://github.com/PrefectHQ/prefect/commit/580af402636c0c37441beb324dd9b0390edf0859"},"participation_stats":[29,39,62,40,31,47,61,54,51,58,60,81,42,50,62,34,29,41,51,57,23,26,29,35,19,12,9,15,29,20,20,29,24,30,21,16,22,27,21,24,21,32,38,28,30,28,35,36,28,29,24,22],"stars":20872,"topics":["automation","data","data-engineering","data-ops","data-science","infrastructure","ml-ops","observability","orchestration","pipeline","prefect","python","workflow","workflow-engine"],"url":"https://github.com/PrefectHQ/prefect","first_commit":{"ts":"2021-07-12T19:36:30Z","url":"https://github.com/PrefectHQ/prefect/commit/5d64e2da1bd11f31d16993ae1730599e13de4016"},"languages":{"Brainfuck":57,"CSS":5115,"Dockerfile":10734,"HTML":2909,"JavaScript":10117,"Jinja":8159,"Just":6714,"Lua":5413,"Mako":589,"Python":17535519,"Shell":10003,"TypeScript":2938673,"Vue":123138},"latest_release":{"ts":"2025-11-19T22:18:43Z","url":"https://github.com/PrefectHQ/prefect/releases/tag/3.6.3"},"license":"Apache License 2.0"},"https://github.com/apache/airflow":{"contributors":{"count":3988,"url":"https://github.com/apache/airflow/graphs/contributors"},"description":"Apache Airflow - A platform to programmatically author, schedule, and monitor workflows","generated_at":"2025-11-20T17:36:42.528926539Z","latest_commit":{"ts":"2025-11-20T16:52:22Z","url":"https://github.com/apache/airflow/commit/b34e63a246daa1ad6a2c27ac782faad5775c7476"},"participation_stats":[122,142,126,99,84,65,91,97,103,155,151,134,101,119,172,149,164,189,174,211,240,152,209,134,159,132,120,121,104,143,215,228,203,174,119,119,133,125,137,134,114,149,181,133,108,51,97,225,217,167,194,128],"stars":43261,"topics":["airflow","apache","apache-airflow","automation","dag","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","elt","etl","machine-learning","mlops","orchestration","python","scheduler","workflow","workflow-engine","workflow-orchestration"],"url":"https://github.com/apache/airflow","first_commit":{"ts":"2014-10-06T21:29:38Z","url":"https://github.com/apache/airflow/commit/1047940ca4363b04044c4963b9c88f7632746407"},"languages":{"CSS":15733,"Dockerfile":126041,"Go":157242,"HCL":3786,"HTML":43841,"Java":1443,"JavaScript":336948,"Jinja":76081,"Jupyter Notebook":7288,"Just":2627,"Mako":2684,"Python":45346457,"Shell":229927,"TypeScript":2845150},"latest_release":{"ts":"2025-11-14T14:47:34Z","url":"https://github.com/apache/airflow/releases/tag/3.1.3"},"license":"Apache License 2.0"},"https://github.com/dagster-io/dagster":{"contributors":{"count":625,"url":"https://github.com/dagster-io/dagster/graphs/contributors"},"description":"An orchestration platform for the development, production, and observation of data assets.","generated_at":"2025-11-20T17:37:00.789915697Z","latest_commit":{"ts":"2025-11-20T17:15:55Z","url":"https://github.com/dagster-io/dagster/commit/fbe63d1577fc7b6b857fd089c5313ccaa0153b20"},"participation_stats":[76,44,120,99,82,39,92,122,139,97,165,142,100,102,109,150,103,102,122,155,122,174,85,100,100,109,111,125,101,63,115,95,48,47,66,101,90,91,94,77,60,52,49,45,48,69,65,30,67,39,38,45],"stars":14450,"topics":["analytics","dagster","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","etl","hacktoberfest","metadata","mlops","orchestration","python","scheduler","workflow","workflow-automation"],"url":"https://github.com/dagster-io/dagster","first_commit":{"ts":"2018-04-30T16:30:04Z","url":"https://github.com/dagster-io/dagster/commit/7bd58d800766aad0c0501539b8f6ee3dbf74331c"},"languages":{"ANTLR":12992,"CSS":67964,"Dockerfile":18351,"HTML":8591,"JavaScript":66858,"Jinja":9253,"Jupyter Notebook":77845,"LookML":329353,"Makefile":12998,"Mako":494,"Mustache":14619,"Python":28515376,"Shell":31993,"Smarty":25391,"TypeScript":6728723},"latest_release":{"ts":"2025-11-13T20:53:06Z","url":"https://github.com/dagster-io/dagster/releases/tag/1.12.2"},"license":"Apache License 2.0"},"https://github.com/mage-ai/mage-ai":{"contributors":{"count":151,"url":"https://github.com/mage-ai/mage-ai/graphs/contributors"},"description":"ðŸ§™ Build, run, and manage data pipelines for integrating and transforming data.","generated_at":"2025-11-20T17:37:30.849439241Z","latest_commit":{"ts":"2025-11-19T22:29:47Z","url":"https://github.com/mage-ai/mage-ai/commit/0a0db6cee5e1defc3a2ca5d24693862fb6a18be1"},"participation_stats":[7,3,0,3,4,0,3,1,8,3,6,8,1,6,4,0,9,3,9,2,3,2,4,5,5,2,4,10,7,6,8,1,3,5,3,5,4,2,2,5,5,6,2,9,2,5,4,3,1,7,8,5],"stars":8561,"topics":["artificial-intelligence","data","data-engineering","data-integration","data-pipelines","data-science","dbt","elt","etl","machine-learning","orchestration","pipeline","pipelines","python","reverse-etl","spark","sql","transformation"],"url":"https://github.com/mage-ai/mage-ai","first_commit":{"ts":"2022-05-16T22:11:41Z","url":"https://github.com/mage-ai/mage-ai/commit/571131f0c298af6d67b03c85a8ea7984c18350d1"},"languages":{"CSS":113518,"Dockerfile":17335,"HTML":1429837,"JavaScript":34527,"Jinja":16315,"Jupyter Notebook":8996,"Makefile":258,"Mako":510,"Python":9181432,"R":134,"SCSS":77261,"Shell":20509,"TypeScript":6093797},"latest_release":{"ts":"2025-09-18T08:10:55Z","url":"https://github.com/mage-ai/mage-ai/releases/tag/0.9.78"},"license":"Apache License 2.0"},"https://github.com/temporalio/temporal":{"contributors":{"count":249,"url":"https://github.com/temporalio/temporal/graphs/contributors"},"description":"Temporal service","generated_at":"2025-11-20T17:38:48.325388532Z","latest_commit":{"ts":"2025-11-19T23:42:39Z","url":"https://github.com/temporalio/temporal/commit/f7ca7745edde45c1498b523fa640bc69944c4d5f"},"participation_stats":[47,20,25,30,18,2,12,25,44,36,51,65,22,28,23,28,30,24,23,26,14,21,21,32,29,15,23,42,17,30,17,21,21,20,20,13,23,14,14,17,17,19,13,24,24,28,15,28,15,21,25,23],"stars":16671,"topics":["cronjob-scheduler","distributed-cron","distributed-systems","golang","microservice-framework","microservice-orchestration","microservices-architecture","orchestrator","service-bus","service-fabric","workflow-automation","workflow-engine","workflow-management","workflow-management-system","workflows"],"url":"https://github.com/temporalio/temporal","first_commit":{"ts":"2016-10-24T23:07:32Z","url":"https://github.com/temporalio/temporal/commit/685242e53fb0c0d9cbdd62fc7725418b528506eb"},"languages":{"Go":20256176,"Makefile":30504,"PLpgSQL":32445,"Python":19117,"Shell":36791},"latest_release":{"ts":"2025-10-29T23:47:24Z","url":"https://github.com/temporalio/temporal/releases/tag/v1.29.1"},"license":"MIT License"},"https://github.com/windmill-labs/windmill":{"contributors":{"count":134,"url":"https://github.com/windmill-labs/windmill/graphs/contributors"},"description":"Open-source developer platform to power your entire infra and turn scripts into webhooks, workflows and UIs. Fastest workflow engine (13x vs Airflow). Open-source alternative to Retool and Temporal.","generated_at":"2025-11-20T17:38:56.736587309Z","latest_commit":{"ts":"2025-11-20T16:23:37Z","url":"https://github.com/windmill-labs/windmill/commit/b56e611700f06844dda4f30d02a1119e714d73a4"},"participation_stats":[51,48,68,68,20,4,23,37,42,64,75,64,84,120,43,50,42,32,48,37,44,44,55,24,36,58,44,33,41,90,64,63,33,72,87,58,45,65,60,53,53,59,66,84,95,57,42,69,103,84,66,87],"stars":15154,"topics":["low-code","open-source","platform","postgresql","python","self-hostable","typescript"],"url":"https://github.com/windmill-labs/windmill","first_commit":{"ts":"2022-05-05T02:25:58Z","url":"https://github.com/windmill-labs/windmill/commit/2e132878e466dd8c5a58a15455919312490f8707"},"languages":{"C":2097,"CSS":85855,"Dockerfile":18219,"Go":6025,"HTML":10614043,"JavaScript":591791,"Nix":15500,"Nushell":17111,"PLpgSQL":36025,"PowerShell":25211,"Python":157933,"RenderScript":1,"Rust":6272867,"Shell":33548,"Svelte":6145973,"TypeScript":2286617},"latest_release":{"ts":"2025-11-20T11:40:34Z","url":"https://github.com/windmill-labs/windmill/releases/tag/v1.581.1"},"license":"Other"}},"items":[{"category":"Automation Tooling","homepage_url":"https://dagster.io/","id":"automation-tooling--workflow-dags--dagster","logo":"logos/3030ac89ff80c2737d3e08baa66c14aaf104b39fcb96a137d304a48d2390ca20.png","name":"Dagster","subcategory":"Workflow DAGs","website":"https://dagster.io/","blog_url":"https://dagster.io/blog","description":"Dagster is a data orchestrator for machine learning, analytics, and ETL. It provides a framework for building, testing, and deploying data pipelines with a focus on developer experience and operational excellence.","documentation_url":"https://docs.dagster.io/","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/dagster-io/dagster/discussions","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/dagster-io/dagster","primary":true}],"summary":{"business_use_case":"Enables reliable and maintainable data pipelines with built-in testing, monitoring, and operational features for data-driven network automation","integration":"dbt, Apache Spark, Kubernetes, Docker, various databases and cloud services","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Data Scientists"],"release_rate":"Regular releases with continuous improvements","tags":["data orchestration","ETL","data pipelines","workflow automation","Python-based"],"use_case":"Data pipeline orchestration, ETL/ELT workflows, machine learning pipelines, network automation data processing"},"tag":["orchestration"]},{"category":"Automation Tooling","homepage_url":"https://prefect.io/","id":"automation-tooling--workflow-dags--prefect","logo":"logos/0adb8100b3649de768b225edb847cc4849e6a0f36d404360d62a92504730a277.svg","name":"Prefect","subcategory":"Workflow DAGs","website":"https://prefect.io/","blog_url":"https://prefect.io/blog","description":"Prefect is a workflow orchestration framework that makes it easy to build, run, and monitor data pipelines. It provides a Python-native approach to workflow automation with strong observability and error handling.","documentation_url":"https://docs.prefect.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/PrefectHQ/prefect","primary":true}],"slack_url":"https://prefect.io/slack","summary":{"business_use_case":"Simplifies complex workflow management with robust error handling, retries, and monitoring for network automation and data processing","integration":"Kubernetes, Docker, AWS, Azure, GCP, dbt, various databases and APIs","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Software Developers"],"release_rate":"Regular releases with active development","tags":["workflow orchestration","Python","data pipelines","distributed computing","observability"],"use_case":"Workflow orchestration, data pipeline automation, network automation tasks, distributed computing"},"tag":["orchestration"]},{"category":"Automation Tooling","homepage_url":"https://www.mage.ai/","id":"automation-tooling--workflow-dags--mage-ai","logo":"logos/e527409ece1839fb83a01fe5514a5d157b17b29c7c723db7b3fc9bbfe1b6a527.png","name":"Mage.ai","subcategory":"Workflow DAGs","website":"https://www.mage.ai/","blog_url":"https://www.mage.ai/blog","description":"Mage is an open-source data pipeline tool for transforming and integrating data. It provides a modern approach to building and deploying data pipelines with a focus on simplicity and developer experience.","documentation_url":"https://docs.mage.ai/","featured":{"label":"Full Open Source","order":1},"maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/mage-ai/mage-ai","primary":true}],"slack_url":"https://www.mage.ai/chat","summary":{"business_use_case":"Accelerates data pipeline development with a visual interface and code-first approach for network data processing and automation","integration":"Various databases, cloud services, APIs, and data sources","personas":["Data Engineers","Data Analysts","Network Engineers","DevOps Engineers"],"release_rate":"Active development with regular updates","tags":["data pipelines","ETL","open-source","visual interface","Python"],"use_case":"Data pipeline development, ETL/ELT workflows, data transformation, network telemetry processing"},"tag":["orchestration"]},{"category":"Automation Tooling","homepage_url":"https://airflow.apache.org","id":"automation-tooling--workflow-dags--apache-airflow","logo":"logos/238f83b507400ed1465c4140bafe0e841c81c208bb81a8c66f987b42d429970a.png","name":"Apache Airflow","subcategory":"Workflow DAGs","website":"https://airflow.apache.org","blog_url":"https://airflow.apache.org/blog","description":"Apache Airflow is an open-source platform that allows for the programmatic creation, scheduling, and monitoring of workflows. It is widely used for orchestrating complex data pipelines and automating tasks across a wide range of industries.","documentation_url":"https://airflow.apache.org/docs","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/apache/airflow/discussions","linkedin_url":"https://www.linkedin.com/company/apache-airflow","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/apache/airflow","primary":true}],"slack_url":"https://apache-airflow.slack.com/","summary":{"business_use_case":"Airflow improves operational efficiency by automating tasks and ensuring seamless integration of data sources, enabling faster and more reliable delivery of insights.","integration":"Supports integration with databases, APIs, cloud services, and external systems to create a unified workflow environment.","personas":["Data Engineers","Data Scientists","DevOps Engineers","IT Operations","Business Analysts"],"release_rate":"Regular updates aligned with the latest advancements in data orchestration and cloud technologies.","tags":["workflow orchestration","data pipelines","automation","ETL","cloud integration","task scheduling"],"use_case":"Orchestrating and scheduling data pipelines, managing ETL processes, and automating complex workflows across diverse environments."},"tag":["orchestration"]},{"category":"Automation Tooling","homepage_url":"https://temporal.io/","id":"automation-tooling--workflow-dags--temporal","logo":"logos/d12d353299e539dd716b2ab211d1b59b23a8ee702cc391bbb3ea6702649e17b5.svg","name":"Temporal","subcategory":"Workflow DAGs","website":"https://temporal.io/","blog_url":"https://temporal.io/blog","description":"Temporal is a microservice orchestration platform that enables developers to build scalable and reliable applications using durable execution.","documentation_url":"https://docs.temporal.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/temporalio/temporal","primary":true}],"slack_url":"https://temporal.io/slack","summary":{"business_use_case":"Simplifies building reliable distributed systems and applications, reducing development time and improving system resilience","integration":"Supports various programming languages (Go, Java, PHP, TypeScript)","personas":["Software Developers","System Architects","DevOps Engineers"],"release_rate":"Regular releases with new features and improvements","tags":["workflow engine","microservices","distributed systems","durable execution","open-source"],"use_case":"Microservice orchestration, workflow automation, distributed systems coordination"},"tag":["orchestration"],"youtube_url":"https://www.youtube.com/temporalio"},{"category":"Automation Tooling","homepage_url":"https://www.windmill.dev","id":"automation-tooling--workflow-dags--windmill","logo":"logos/a76d60938f3260cb0b65b065c221da39941a18cea838f075fe4c8ee55d2deb97.svg","name":"Windmill","subcategory":"Workflow DAGs","website":"https://www.windmill.dev","blog_url":"https://www.windmill.dev/blog","crunchbase_url":"https://www.crunchbase.com/organization/windmill-labs","description":"Windmill is an open-source workflow engine and developer platform that turns scripts into auto-generated UIs, APIs, and workflows. Supporting 20+ languages including Python, TypeScript, Go, and Bash, it provides a code-first approach to automation with low-code visual workflow builders and comprehensive observability.","discord_url":"https://discord.gg/V7PM2YHsPB","docker_url":"https://hub.docker.com/r/windmilllabs/windmill","documentation_url":"https://www.windmill.dev/docs/intro","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"github_discussions_url":"https://github.com/windmill-labs/windmill/discussions","maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/windmill-labs/windmill","primary":true}],"summary":{"business_use_case":"Accelerates automation development by turning scripts into production-grade workflows and internal tools 10x faster, with high performance orchestration (13x faster than Airflow) and comprehensive observability","integration":"Webhooks, REST APIs, Slack, PostgreSQL, Git, VS Code, CLI tools, AWS, Azure, GCP, and 100+ integrations","personas":["DevOps Engineers","Platform Engineers","Software Developers","Site Reliability Engineers","Data Engineers"],"release_rate":"Regular updates with community-driven development","tags":["workflow engine","script automation","internal tools","multi-language","low-code","observability","API orchestration","developer platform"],"use_case":"Script-to-workflow automation, internal tool building, API orchestration, scheduled jobs, and data pipeline management with auto-generated UIs and multi-language support"},"tag":["orchestration"]}]}