{"github_data":{"https://github.com/PrefectHQ/prefect":{"contributors":{"count":379,"url":"https://github.com/PrefectHQ/prefect/graphs/contributors"},"description":"Prefect is a workflow orchestration framework for building resilient data pipelines in Python.","generated_at":"2025-11-19T20:47:07.198315415Z","latest_commit":{"ts":"2025-11-19T19:09:10Z","url":"https://github.com/PrefectHQ/prefect/commit/4eaf5c7ad600695aad453f32fd605b61230da179"},"participation_stats":[25,34,63,45,37,45,56,51,55,55,58,87,29,60,55,42,33,39,45,61,23,31,26,36,22,14,6,13,28,24,18,31,20,27,24,22,18,28,22,23,21,33,32,31,29,31,36,35,26,21,35,20],"stars":20868,"topics":["automation","data","data-engineering","data-ops","data-science","infrastructure","ml-ops","observability","orchestration","pipeline","prefect","python","workflow","workflow-engine"],"url":"https://github.com/PrefectHQ/prefect","first_commit":{"ts":"2021-07-12T19:36:30Z","url":"https://github.com/PrefectHQ/prefect/commit/5d64e2da1bd11f31d16993ae1730599e13de4016"},"languages":{"Brainfuck":57,"CSS":5115,"Dockerfile":10734,"HTML":2909,"JavaScript":10117,"Jinja":8159,"Just":6714,"Lua":5413,"Mako":589,"Python":17535519,"Shell":10003,"TypeScript":2938673,"Vue":123138},"latest_release":{"ts":"2025-11-14T00:14:01Z","url":"https://github.com/PrefectHQ/prefect/releases/tag/3.6.2"},"license":"Apache License 2.0"},"https://github.com/apache/airflow":{"contributors":{"count":3988,"url":"https://github.com/apache/airflow/graphs/contributors"},"description":"Apache Airflow - A platform to programmatically author, schedule, and monitor workflows","generated_at":"2025-11-19T20:47:18.448709375Z","latest_commit":{"ts":"2025-11-19T19:48:16Z","url":"https://github.com/apache/airflow/commit/829bc6e2fdaf87e34559fc4d4d587ff8c5b35901"},"participation_stats":[111,150,127,95,103,54,88,97,102,153,145,136,113,107,165,157,160,192,168,195,246,149,219,152,150,128,129,130,96,139,210,228,200,192,112,120,126,128,135,144,103,149,181,135,112,64,82,183,259,157,209,131],"stars":43251,"topics":["airflow","apache","apache-airflow","automation","dag","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","elt","etl","machine-learning","mlops","orchestration","python","scheduler","workflow","workflow-engine","workflow-orchestration"],"url":"https://github.com/apache/airflow","first_commit":{"ts":"2014-10-06T21:29:38Z","url":"https://github.com/apache/airflow/commit/1047940ca4363b04044c4963b9c88f7632746407"},"languages":{"CSS":15733,"Dockerfile":126041,"Go":157242,"HCL":3786,"HTML":43841,"Java":1443,"JavaScript":336948,"Jinja":76081,"Jupyter Notebook":7288,"Just":2627,"Mako":2684,"Python":45244731,"Shell":229927,"TypeScript":2844451},"latest_release":{"ts":"2025-11-14T14:47:34Z","url":"https://github.com/apache/airflow/releases/tag/3.1.3"},"license":"Apache License 2.0"},"https://github.com/dagster-io/dagster":{"contributors":{"count":625,"url":"https://github.com/dagster-io/dagster/graphs/contributors"},"description":"An orchestration platform for the development, production, and observation of data assets.","generated_at":"2025-11-19T20:47:31.118141634Z","latest_commit":{"ts":"2025-11-19T20:14:20Z","url":"https://github.com/dagster-io/dagster/commit/5bd672515139d167b2a010f9001a7d58e04e7a1f"},"participation_stats":[63,60,114,96,97,41,79,117,120,118,124,178,94,116,96,146,114,106,116,141,138,160,109,105,85,113,103,121,120,58,95,107,57,55,47,97,94,104,90,84,49,59,45,46,45,64,80,29,63,46,39,35],"stars":14446,"topics":["analytics","dagster","data-engineering","data-integration","data-orchestrator","data-pipelines","data-science","etl","hacktoberfest","metadata","mlops","orchestration","python","scheduler","workflow","workflow-automation"],"url":"https://github.com/dagster-io/dagster","first_commit":{"ts":"2018-04-30T16:30:04Z","url":"https://github.com/dagster-io/dagster/commit/7bd58d800766aad0c0501539b8f6ee3dbf74331c"},"languages":{"ANTLR":12992,"CSS":67964,"Dockerfile":18351,"HTML":8591,"JavaScript":66858,"Jinja":9253,"Jupyter Notebook":77845,"LookML":329353,"Makefile":12998,"Mako":494,"Mustache":14619,"Python":28514347,"Shell":31993,"Smarty":25391,"TypeScript":6728664},"latest_release":{"ts":"2025-11-13T20:53:06Z","url":"https://github.com/dagster-io/dagster/releases/tag/1.12.2"},"license":"Apache License 2.0"},"https://github.com/mage-ai/mage-ai":{"contributors":{"count":151,"url":"https://github.com/mage-ai/mage-ai/graphs/contributors"},"description":"ðŸ§™ Build, run, and manage data pipelines for integrating and transforming data.","generated_at":"2025-11-19T20:47:53.913919660Z","latest_commit":{"ts":"2025-11-19T18:22:03Z","url":"https://github.com/mage-ai/mage-ai/commit/9b1f0e6db1c58c32288f70c6f59929729cd07ca4"},"participation_stats":[6,3,1,2,5,0,2,2,8,2,7,6,3,6,2,2,9,3,9,2,3,1,3,5,7,1,4,7,9,6,9,1,3,5,3,6,4,1,3,4,3,9,2,9,1,5,5,2,2,7,7,4],"stars":8560,"topics":["artificial-intelligence","data","data-engineering","data-integration","data-pipelines","data-science","dbt","elt","etl","machine-learning","orchestration","pipeline","pipelines","python","reverse-etl","spark","sql","transformation"],"url":"https://github.com/mage-ai/mage-ai","first_commit":{"ts":"2022-05-16T22:11:41Z","url":"https://github.com/mage-ai/mage-ai/commit/571131f0c298af6d67b03c85a8ea7984c18350d1"},"languages":{"CSS":113518,"Dockerfile":17335,"HTML":1429837,"JavaScript":34527,"Jinja":16315,"Jupyter Notebook":8996,"Makefile":258,"Mako":510,"Python":9181432,"R":134,"SCSS":77261,"Shell":20509,"TypeScript":6093797},"latest_release":{"ts":"2025-09-18T08:10:55Z","url":"https://github.com/mage-ai/mage-ai/releases/tag/0.9.78"},"license":"Apache License 2.0"},"https://github.com/temporalio/temporal":{"contributors":{"count":249,"url":"https://github.com/temporalio/temporal/graphs/contributors"},"description":"Temporal service","generated_at":"2025-11-19T20:48:47.181984528Z","latest_commit":{"ts":"2025-11-19T18:37:18Z","url":"https://github.com/temporalio/temporal/commit/d9d2f62bed13f61c421168c9967b222244e29f46"},"participation_stats":[43,23,25,30,22,2,6,25,42,37,42,75,22,26,27,30,24,30,19,30,11,19,21,35,30,18,13,50,13,29,16,22,25,19,20,13,22,15,15,17,15,21,13,25,19,29,16,32,15,21,19,24],"stars":16658,"topics":["cronjob-scheduler","distributed-cron","distributed-systems","golang","microservice-framework","microservice-orchestration","microservices-architecture","orchestrator","service-bus","service-fabric","workflow-automation","workflow-engine","workflow-management","workflow-management-system","workflows"],"url":"https://github.com/temporalio/temporal","first_commit":{"ts":"2016-10-24T23:07:32Z","url":"https://github.com/temporalio/temporal/commit/685242e53fb0c0d9cbdd62fc7725418b528506eb"},"languages":{"Go":20256138,"Makefile":30504,"PLpgSQL":32445,"Python":19117,"Shell":36791},"latest_release":{"ts":"2025-10-29T23:47:24Z","url":"https://github.com/temporalio/temporal/releases/tag/v1.29.1"},"license":"MIT License"}},"items":[{"category":"Automation Tooling","homepage_url":"https://dagster.io/","id":"automation-tooling--workflow-dags--dagster","logo":"logos/3030ac89ff80c2737d3e08baa66c14aaf104b39fcb96a137d304a48d2390ca20.png","name":"Dagster","subcategory":"Workflow DAGs","website":"https://dagster.io/","blog_url":"https://dagster.io/blog","description":"Dagster is a data orchestrator for machine learning, analytics, and ETL. It provides a framework for building, testing, and deploying data pipelines with a focus on developer experience and operational excellence.","documentation_url":"https://docs.dagster.io/","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/dagster-io/dagster/discussions","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/dagster-io/dagster","primary":true}],"summary":{"business_use_case":"Enables reliable and maintainable data pipelines with built-in testing, monitoring, and operational features for data-driven network automation","integration":"dbt, Apache Spark, Kubernetes, Docker, various databases and cloud services","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Data Scientists"],"release_rate":"Regular releases with continuous improvements","tags":["data orchestration","ETL","data pipelines","workflow automation","Python-based"],"use_case":"Data pipeline orchestration, ETL/ELT workflows, machine learning pipelines, network automation data processing"}},{"category":"Automation Tooling","homepage_url":"https://prefect.io/","id":"automation-tooling--workflow-dags--prefect","logo":"logos/0adb8100b3649de768b225edb847cc4849e6a0f36d404360d62a92504730a277.svg","name":"Prefect","subcategory":"Workflow DAGs","website":"https://prefect.io/","blog_url":"https://prefect.io/blog","description":"Prefect is a workflow orchestration framework that makes it easy to build, run, and monitor data pipelines. It provides a Python-native approach to workflow automation with strong observability and error handling.","documentation_url":"https://docs.prefect.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/PrefectHQ/prefect","primary":true}],"slack_url":"https://prefect.io/slack","summary":{"business_use_case":"Simplifies complex workflow management with robust error handling, retries, and monitoring for network automation and data processing","integration":"Kubernetes, Docker, AWS, Azure, GCP, dbt, various databases and APIs","personas":["Data Engineers","DevOps Engineers","Network Automation Engineers","Software Developers"],"release_rate":"Regular releases with active development","tags":["workflow orchestration","Python","data pipelines","distributed computing","observability"],"use_case":"Workflow orchestration, data pipeline automation, network automation tasks, distributed computing"}},{"category":"Automation Tooling","homepage_url":"https://www.mage.ai/","id":"automation-tooling--workflow-dags--mage-ai","logo":"logos/e527409ece1839fb83a01fe5514a5d157b17b29c7c723db7b3fc9bbfe1b6a527.png","name":"Mage.ai","subcategory":"Workflow DAGs","website":"https://www.mage.ai/","blog_url":"https://www.mage.ai/blog","description":"Mage is an open-source data pipeline tool for transforming and integrating data. It provides a modern approach to building and deploying data pipelines with a focus on simplicity and developer experience.","documentation_url":"https://docs.mage.ai/","featured":{"label":"Full Open Source","order":1},"maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/mage-ai/mage-ai","primary":true}],"slack_url":"https://www.mage.ai/chat","summary":{"business_use_case":"Accelerates data pipeline development with a visual interface and code-first approach for network data processing and automation","integration":"Various databases, cloud services, APIs, and data sources","personas":["Data Engineers","Data Analysts","Network Engineers","DevOps Engineers"],"release_rate":"Active development with regular updates","tags":["data pipelines","ETL","open-source","visual interface","Python"],"use_case":"Data pipeline development, ETL/ELT workflows, data transformation, network telemetry processing"}},{"category":"Automation Tooling","homepage_url":"https://airflow.apache.org","id":"automation-tooling--workflow-dags--apache-airflow","logo":"logos/238f83b507400ed1465c4140bafe0e841c81c208bb81a8c66f987b42d429970a.png","name":"Apache Airflow","subcategory":"Workflow DAGs","website":"https://airflow.apache.org","blog_url":"https://airflow.apache.org/blog","description":"Apache Airflow is an open-source platform that allows for the programmatic creation, scheduling, and monitoring of workflows. It is widely used for orchestrating complex data pipelines and automating tasks across a wide range of industries.","documentation_url":"https://airflow.apache.org/docs","featured":{"label":"Full Open Source","order":1},"github_discussions_url":"https://github.com/apache/airflow/discussions","linkedin_url":"https://www.linkedin.com/company/apache-airflow","maturity":"full-open-source","oss":true,"repositories":[{"url":"https://github.com/apache/airflow","primary":true}],"slack_url":"https://apache-airflow.slack.com/","summary":{"business_use_case":"Airflow improves operational efficiency by automating tasks and ensuring seamless integration of data sources, enabling faster and more reliable delivery of insights.","integration":"Supports integration with databases, APIs, cloud services, and external systems to create a unified workflow environment.","personas":["Data Engineers","Data Scientists","DevOps Engineers","IT Operations","Business Analysts"],"release_rate":"Regular updates aligned with the latest advancements in data orchestration and cloud technologies.","tags":["workflow orchestration","data pipelines","automation","ETL","cloud integration","task scheduling"],"use_case":"Orchestrating and scheduling data pipelines, managing ETL processes, and automating complex workflows across diverse environments."}},{"category":"Automation Tooling","homepage_url":"https://temporal.io/","id":"automation-tooling--workflow-dags--temporal","logo":"logos/d12d353299e539dd716b2ab211d1b59b23a8ee702cc391bbb3ea6702649e17b5.svg","name":"Temporal","subcategory":"Workflow DAGs","website":"https://temporal.io/","blog_url":"https://temporal.io/blog","description":"Temporal is a microservice orchestration platform that enables developers to build scalable and reliable applications using durable execution.","documentation_url":"https://docs.temporal.io/","featured":{"label":"Hybrid (Open Core with Proprietary Extensions)","order":8},"maturity":"hybrid","oss":true,"repositories":[{"url":"https://github.com/temporalio/temporal","primary":true}],"slack_url":"https://temporal.io/slack","summary":{"business_use_case":"Simplifies building reliable distributed systems and applications, reducing development time and improving system resilience","integration":"Supports various programming languages (Go, Java, PHP, TypeScript)","personas":["Software Developers","System Architects","DevOps Engineers"],"release_rate":"Regular releases with new features and improvements","tags":["workflow engine","microservices","distributed systems","durable execution","open-source"],"use_case":"Microservice orchestration, workflow automation, distributed systems coordination"},"youtube_url":"https://www.youtube.com/temporalio"}]}